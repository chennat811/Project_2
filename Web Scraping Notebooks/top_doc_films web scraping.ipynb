{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-207-d7cdcd16b49c>:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from time import sleep\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "from collections import Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-agent': 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/44.0.2403.155 Safari/537.36'}\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent()\n",
    "user_agent = {'User-agent': ua.random}\n",
    "print(user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:10.0) Gecko/20100101 Firefox/62.0'}\n",
      "['Technology', 'Sports', 'Society', 'Sexuality', 'Science', 'Religion', 'Psychology', 'Politics', 'Philosophy', 'Performing Arts', 'Nature', 'Mystery', 'Military and War', 'Media', 'History', 'Health', 'Environment', 'Economics', 'Drugs', 'Crime', 'Conspiracy', 'Biography', 'Art and Artists', '9/11'] ['https://topdocumentaryfilms.com/category/technology/', 'https://topdocumentaryfilms.com/category/sports/', 'https://topdocumentaryfilms.com/category/society/', 'https://topdocumentaryfilms.com/category/sex/', 'https://topdocumentaryfilms.com/category/science-technology/', 'https://topdocumentaryfilms.com/category/religion/', 'https://topdocumentaryfilms.com/category/psychology/', 'https://topdocumentaryfilms.com/category/politics/', 'https://topdocumentaryfilms.com/category/philosophy/', 'https://topdocumentaryfilms.com/category/music-performing-arts/', 'https://topdocumentaryfilms.com/category/nature-wildlife/', 'https://topdocumentaryfilms.com/category/mystery/', 'https://topdocumentaryfilms.com/category/military-war/', 'https://topdocumentaryfilms.com/category/media/', 'https://topdocumentaryfilms.com/category/history/', 'https://topdocumentaryfilms.com/category/health/', 'https://topdocumentaryfilms.com/category/environment/', 'https://topdocumentaryfilms.com/category/economics/', 'https://topdocumentaryfilms.com/category/drugs/', 'https://topdocumentaryfilms.com/category/crime/', 'https://topdocumentaryfilms.com/category/crime-conspiracy/', 'https://topdocumentaryfilms.com/category/biography/', 'https://topdocumentaryfilms.com/category/art-artists/', 'https://topdocumentaryfilms.com/category/911/']\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent()\n",
    "user_agent = {'User-agent': ua.random}\n",
    "print(user_agent)\n",
    "sleep(random.randint(3, 7))\n",
    "response = requests.get('https://topdocumentaryfilms.com/watch-online/', headers = user_agent)\n",
    "#response\n",
    "soup = BeautifulSoup(response.text, 'html5lib')\n",
    "main = soup.find(class_='module')\n",
    "categories = main.find_all('div', class_='sitemap-wraper clear')\n",
    "cat_list = []\n",
    "links = []\n",
    "num_in_cat = []\n",
    "for i in categories:\n",
    "    cat = i.find('a').text\n",
    "    cat_list.append(cat)\n",
    "    link = i.find('a').get('href')\n",
    "    links.append(link)\n",
    "print(cat_list, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst):\n",
    "    rt = []\n",
    "    for i in lst:\n",
    "        if isinstance(i, list): rt.extend(flatten(i))\n",
    "        else:rt.append(i)\n",
    "    return rt\n",
    "\n",
    "links_to_click = []\n",
    "for link in links:\n",
    "    temp = []\n",
    "    i=1\n",
    "    url = link\n",
    "    links_to_click.append(url)\n",
    "    while True:\n",
    "        i = i+1\n",
    "        page = requests.get(url, headers = user_agent)\n",
    "        if page.status_code != 200:\n",
    "            break\n",
    "        url = link + \"page/\" + str(i) + \"/\"\n",
    "        temp.append(url)\n",
    "        cleaned = temp[0:(len(temp)-1)]\n",
    "    links_to_click.append(cleaned)\n",
    "final_list = flatten(links_to_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "categories = []\n",
    "years = []\n",
    "ratings = []\n",
    "for item in final_list:\n",
    "    source_code = requests.get(item, headers = user_agent)\n",
    "    soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "    main = soup.find(class_='group grid')\n",
    "    result = main.find_all('h2')\n",
    "    for i in result:\n",
    "        try:\n",
    "            title = i.text\n",
    "            titles.append(title)\n",
    "        except AttributeError:\n",
    "            titles.append('NaN')\n",
    "    result2 = main.find_all('article', class_='module')\n",
    "    for i in result2:\n",
    "        year_cat = i.find('div', class_='meta-bar').contents\n",
    "        try:\n",
    "            year = year_cat[0].strip('\\n')\n",
    "            final_year = year.strip(',\\t')\n",
    "            years.append(final_year)\n",
    "        except AttributeError:\n",
    "            years.append('NaN')\n",
    "        try:\n",
    "            cat = i.find(rel = 'category tag').text\n",
    "            categories.append(cat)\n",
    "        except AttributeError:\n",
    "            categories.append('NaN')\n",
    "    result3 = main.find_all(class_='archive_rating')\n",
    "    for i in result3:\n",
    "        try:\n",
    "            rating = i.text.strip('★ ')\n",
    "            ratings.append(rating)\n",
    "        except AttributeError:\n",
    "            ratings.append('NaN')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>User Rating - Top Doc</th>\n",
       "      <th>Years</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Printing Out the World</td>\n",
       "      <td>7.77</td>\n",
       "      <td>2019</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Big Reset 2.0</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2020</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlphaGo</td>\n",
       "      <td>8.06</td>\n",
       "      <td>2017</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlie and the Humans</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2019</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Into the Unknown</td>\n",
       "      <td>8.40</td>\n",
       "      <td>2016</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>The Ultimate Con</td>\n",
       "      <td>8.68</td>\n",
       "      <td>2007</td>\n",
       "      <td>9/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>9/11 Mysteries</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2006</td>\n",
       "      <td>9/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>Towers of Deception: The Media Cover-Up of 9/11</td>\n",
       "      <td>7.78</td>\n",
       "      <td>2003</td>\n",
       "      <td>9/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>In Their Own Words: The Untold Stories of the ...</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2006</td>\n",
       "      <td>9/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>Fahrenheit 9/11</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2004</td>\n",
       "      <td>9/11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2549 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title User Rating - Top Doc  \\\n",
       "0                                Printing Out the World                  7.77   \n",
       "1                                     The Big Reset 2.0                  7.33   \n",
       "2                                               AlphaGo                  8.06   \n",
       "3                                Charlie and the Humans                  7.38   \n",
       "4                                      Into the Unknown                  8.40   \n",
       "...                                                 ...                   ...   \n",
       "2544                                   The Ultimate Con                  8.68   \n",
       "2545                                     9/11 Mysteries                  8.10   \n",
       "2546    Towers of Deception: The Media Cover-Up of 9/11                  7.78   \n",
       "2547  In Their Own Words: The Untold Stories of the ...                  7.64   \n",
       "2548                                    Fahrenheit 9/11                  5.80   \n",
       "\n",
       "     Years    Category  \n",
       "0     2019  Technology  \n",
       "1     2020  Technology  \n",
       "2     2017  Technology  \n",
       "3     2019  Technology  \n",
       "4     2016  Technology  \n",
       "...    ...         ...  \n",
       "2544  2007        9/11  \n",
       "2545  2006        9/11  \n",
       "2546  2003        9/11  \n",
       "2547  2006        9/11  \n",
       "2548  2004        9/11  \n",
       "\n",
       "[2549 rows x 4 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = dict({'Title':titles, 'User Rating - Top Doc':ratings, 'Years': years, 'Category':categories})\n",
    "df = pd.DataFrame(dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('top_doc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Printing Out the World'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = soup.find(class_='group grid')\n",
    "result = main.find_all(class_='excerptpic')\n",
    "#to get the title\n",
    "just_one.find('a').get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = main.find_all('article', class_='module')\n",
    "year_cat = result2[0].find('div', class_='meta-bar').contents\n",
    "year = year_cat[0].strip('\\n')\n",
    "final_year = year.strip(',\\t')\n",
    "#cat = result2[0].find(')\n",
    "#year_cat = result2[0].text.split(',')\n",
    "#year = year_cat[0].strip('\\n').split('\\n\\n')[1]\n",
    "#cat = year_cat[1].strip('\\t').split('  \\n')[0]\n",
    "cat = result2[0].find(rel = 'category tag').text\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.77'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = main.find_all(class_='archive_rating')\n",
    "rating = result3[0].text.strip('★ ')\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://topdocumentaryfilms.com/category/sports/page/2/', 'https://topdocumentaryfilms.com/category/sports/page/3/', 'https://topdocumentaryfilms.com/category/sports/page/4/']\n"
     ]
    }
   ],
   "source": [
    "print(list_links[1:4]) #use pagination module at the end of the page to find the stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"pagination module\"><span class=\"current\">1</span><a class=\"inactive\" href=\"https://topdocumentaryfilms.com/category/technology/page/2/\">2</a>... <a href=\"https://topdocumentaryfilms.com/category/technology/page/10/\">10</a><a href=\"https://topdocumentaryfilms.com/category/technology/page/2/\">Next</a></div>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4 = main.find(class_='pagination module')\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_=result4.find_all('a')[2].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://topdocumentaryfilms.com/category/technology/page/2/'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://topdocumentaryfilms.com/category/sports/']\n",
      "['https://topdocumentaryfilms.com/category/sports/', []]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#to get the links of each subsequent page \n",
    "i=2\n",
    "links_in_cat = []\n",
    "temp = []\n",
    "links_in_cat.append('https://topdocumentaryfilms.com/category/sports/')\n",
    "print(links_in_cat)\n",
    "\n",
    "while True:\n",
    "    i = i+1\n",
    "    page = requests.get(url, headers = user_agent)\n",
    "    if page.status_code != 200:\n",
    "        break\n",
    "    url = 'https://topdocumentaryfilms.com/category/sports/' + \"page/\" + str(i) + \"/\"\n",
    "    temp.append(url)\n",
    "cleaned = temp[1:(len(temp)-1)]\n",
    "links_in_cat.append(cleaned)\n",
    "print(links_in_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def flatten(coll):\n",
    "    for i in coll:\n",
    "        if isinstance(i, Iterable) and not isinstance(i, basestring):\n",
    "            for subc in flatten(i):\n",
    "                yield subc\n",
    "        else:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "links_to_click = []\n",
    "temp = []\n",
    "i=1\n",
    "url = 'https://topdocumentaryfilms.com/category/sports/'\n",
    "links_to_click.append(url)\n",
    "while True:\n",
    "    i = i+1\n",
    "    page = requests.get(url, headers = user_agent)\n",
    "    if page.status_code != 200:\n",
    "        break\n",
    "    url = 'https://topdocumentaryfilms.com/category/sports/' + \"page/\" + str(i) + \"/\"\n",
    "    temp.append(url)\n",
    "    cleaned = temp[0:(len(temp)-1)]\n",
    "links_to_click.append(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-294-89b6e923d530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0myear_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myear_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0myears\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'''\n",
    "titles = []\n",
    "categories = []\n",
    "years = []\n",
    "ratings = []\n",
    "for item in final_list[:2]:\n",
    "    source_code = requests.get(item, headers = user_agent)\n",
    "    soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "    main = soup.find(class_='group grid')\n",
    "    result = main.find_all(class_='excerptpic')\n",
    "    for i in result:\n",
    "        try:\n",
    "            title = i.find('a').get('title')\n",
    "            titles.append(title)\n",
    "        except AttributeError:\n",
    "            titles.append('NaN')\n",
    "    result2 = main.find_all('article', class_='module')\n",
    "    for i in result2:\n",
    "        year_cat = i.find('div', class_='meta-bar')\n",
    "        year_cat = i.text.split(',')\n",
    "        try:\n",
    "            year = year_cat[0].strip('\\n').split('\\n\\n')[1]\n",
    "            years.append(year)\n",
    "        except AttributeError:\n",
    "            titles.append('NaN')\n",
    "        try:\n",
    "            cat = year_cat[1].strip('\\t').split('  \\n')[0]\n",
    "            categories.append(cat)\n",
    "        except AttributeError:\n",
    "            categories.append('NaN')\n",
    "    result3 = main.find_all(class_='archive_rating')\n",
    "    for i in result3:\n",
    "        try:\n",
    "            rating = i.text.strip('★ ')\n",
    "            ratings.append(rating)\n",
    "        except AttributeError:\n",
    "            ratings.append('NaN')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2549"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Playing God', 'In the Realm of the Hackers', 'Build It Bigger: Floating City', 'Tetris: From Russia with Love', 'Future Intelligence', 'Can You Hack It? - Hackers Wanted', 'A Machine to Die For: The Quest for Free Energy', 'The Betrayal by Technology: A Portrait of Jacques Ellul', 'Inventions That Changed the World', 'Future by Design', 'Revolution OS', 'The Virtual Revolution', 'Dubai Palm Islands', 'World Trade Center', 'James Burke: Connections', 'The Machine That Made Us', 'Download: The True Story of the Internet', 'Carrier', 'Battle of the X-Planes', 'Car of the Future', 'Nerds 2.0.1: A Brief History of the Internet', 'Triumph of the Nerds: The Rise of Accidental Empires', 'Trinity and Beyond: The Atomic Bomb Movie', 'The Machine That Changed the World']\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "for item in final_list[7:9]:\n",
    "    source_code = requests.get(item, headers = user_agent)\n",
    "    soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "    main = soup.find(class_='group grid')\n",
    "    result = main.find_all('h2')\n",
    "    for i in result:\n",
    "        title = i.text\n",
    "        titles.append(title)\n",
    "print(titles)\n",
    "    #for i in result:\n",
    "    #    title = \n",
    "#    for i in result:\n",
    "#        try:\n",
    "#            title = i.find('a').get('title')\n",
    "#            titles.append(title)\n",
    "#        except AttributeError:\n",
    "#            titles.append('NaN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

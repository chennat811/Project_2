{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from time import sleep\n",
    "import random\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sleep(random.randint(3, 7))\n",
    "titles = []\n",
    "links = []\n",
    "links_list = ['https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250', \n",
    "              'https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250&start=251&ref_=adv_nxt', \n",
    "              'https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250&start=501&ref_=adv_nxt', \n",
    "              'https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250&start=751&ref_=adv_nxt']\n",
    "for i in links_list:\n",
    "    titles_interim =[]\n",
    "    source_code =  requests.get(i)\n",
    "    soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "    results = soup.find_all(class_='lister-item-content')\n",
    "    for i in range(len(results)):\n",
    "        title = results[i].find('a').contents\n",
    "        titles_interim.append(title)\n",
    "    for i in titles_interim:\n",
    "        titles.append(i[0])\n",
    "        \n",
    "    results = soup.find_all(class_='lister-item-content')\n",
    "    for i in range(len(results)):\n",
    "        link = results[i].find('a').get('href')\n",
    "        full_link = \"https://www.imdb.com\" + link + \"?ref_=adv_li_tt\"\n",
    "        links.append(full_link)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(random.randint(3, 7))\n",
    "titles = []\n",
    "links = []\n",
    "links_list = ['https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250', \n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=251&ref_=adv_nxt', \n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=501&ref_=adv_nxt', \n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=751&ref_=adv_nxt',\n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=1001&ref_=adv_nxt',\n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=1251&ref_=adv_nxt',\n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=1501&ref_=adv_nxt', \n",
    "              'https://www.imdb.com/search/title/?title_type=documentary&sort=num_votes,desc&count=250&start=1751&ref_=adv_nxt']\n",
    "for i in links_list:\n",
    "    titles_interim =[]\n",
    "    source_code =  requests.get(i)\n",
    "    soup = BeautifulSoup(source_code.text, 'html5lib')\n",
    "    results = soup.find_all(class_='lister-item-content')\n",
    "    for i in range(len(results)):\n",
    "        title = results[i].find('a').contents\n",
    "        titles_interim.append(title)\n",
    "    for i in titles_interim:\n",
    "        titles.append(i[0])\n",
    "        \n",
    "    results = soup.find_all(class_='lister-item-content')\n",
    "    for i in range(len(results)):\n",
    "        link = results[i].find('a').get('href')\n",
    "        full_link = \"https://www.imdb.com\" + link + \"?ref_=adv_li_tt\"\n",
    "        links.append(full_link)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating = []\n",
    "metacritic = []\n",
    "num_votes = []\n",
    "running_time=[]\n",
    "release_date = []\n",
    "director = []\n",
    "for link in links:\n",
    "    soup = BeautifulSoup(requests.get(link).text, \"html5lib\")\n",
    "    try:\n",
    "        user_rating.append(soup.find(itemprop='ratingValue').text)\n",
    "    except AttributeError:\n",
    "        user_rating.append('N/A')\n",
    "    try:\n",
    "        num_votes.append(soup.find('span', class_='small', itemprop='ratingCount').text)\n",
    "    except AttributeError:\n",
    "        num_votes.append('N/A')\n",
    "    try:\n",
    "        running_time.append(soup.find('div', class_='subtext').time.text.strip())\n",
    "    except AttributeError:\n",
    "        running_time.append('N/A')\n",
    "    try:\n",
    "        release_date.append(soup.find('a', title='See more release dates').text.strip())\n",
    "    except AttributeError:\n",
    "        release_date.append('N/A')\n",
    "    try:\n",
    "        director.append(soup.find_all('div', class_='credit_summary_item')[0].a.text)\n",
    "    except AttributeError:\n",
    "        director.append('N/A')\n",
    "    except IndexError:\n",
    "        director.append('N/A')            \n",
    "    try:\n",
    "        metacritic.append(soup.find(class_='metacriticScore score_favorable titleReviewBarSubItem').text.strip())\n",
    "    except AttributeError:\n",
    "        metacritic.append('N/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>User Rating_IMDB</th>\n",
       "      <th>Metacritic</th>\n",
       "      <th>Number of Votes_IMDB</th>\n",
       "      <th>Running Time</th>\n",
       "      <th>Release Date_IMDB</th>\n",
       "      <th>Director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bowling for Columbine</td>\n",
       "      <td>7.9</td>\n",
       "      <td>72</td>\n",
       "      <td>138,833</td>\n",
       "      <td>2h</td>\n",
       "      <td>15 November 2002 (USA)</td>\n",
       "      <td>Michael Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fahrenheit 9/11</td>\n",
       "      <td>7.5</td>\n",
       "      <td>67</td>\n",
       "      <td>125,629</td>\n",
       "      <td>2h 2min</td>\n",
       "      <td>25 June 2004 (USA)</td>\n",
       "      <td>Michael Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Size Me</td>\n",
       "      <td>7.2</td>\n",
       "      <td>73</td>\n",
       "      <td>100,146</td>\n",
       "      <td>1h 40min</td>\n",
       "      <td>11 June 2004 (USA)</td>\n",
       "      <td>Morgan Spurlock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jackass: The Movie</td>\n",
       "      <td>6.6</td>\n",
       "      <td>N/A</td>\n",
       "      <td>80,546</td>\n",
       "      <td>1h 27min</td>\n",
       "      <td>25 October 2002 (USA)</td>\n",
       "      <td>Jeff Tremaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Inconvenient Truth</td>\n",
       "      <td>7.4</td>\n",
       "      <td>75</td>\n",
       "      <td>79,832</td>\n",
       "      <td>1h 36min</td>\n",
       "      <td>30 June 2006 (USA)</td>\n",
       "      <td>Davis Guggenheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Ron White: You Can't Fix Stupid</td>\n",
       "      <td>7.4</td>\n",
       "      <td>N/A</td>\n",
       "      <td>914</td>\n",
       "      <td>1h</td>\n",
       "      <td>TV Special 25 March 2006</td>\n",
       "      <td>Michael Drumm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>A Grin Without A Cat</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81</td>\n",
       "      <td>914</td>\n",
       "      <td>4h</td>\n",
       "      <td>23 November 1977 (France)</td>\n",
       "      <td>Chris Marker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Le chant du Styrène</td>\n",
       "      <td>7.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>914</td>\n",
       "      <td>13min</td>\n",
       "      <td>November 1958 (France)</td>\n",
       "      <td>Alain Resnais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Prison Break: The Road to Freedom</td>\n",
       "      <td>8.4</td>\n",
       "      <td>N/A</td>\n",
       "      <td>913</td>\n",
       "      <td>22min</td>\n",
       "      <td>TV Short 13 January 2007</td>\n",
       "      <td>Jim Barrett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The Lovers &amp; the Despot</td>\n",
       "      <td>6.5</td>\n",
       "      <td>65</td>\n",
       "      <td>912</td>\n",
       "      <td>1h 38min</td>\n",
       "      <td>23 September 2016 (USA)</td>\n",
       "      <td>Ross Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title User Rating_IMDB Metacritic  \\\n",
       "0                 Bowling for Columbine              7.9         72   \n",
       "1                       Fahrenheit 9/11              7.5         67   \n",
       "2                         Super Size Me              7.2         73   \n",
       "3                    Jackass: The Movie              6.6        N/A   \n",
       "4                 An Inconvenient Truth              7.4         75   \n",
       "...                                 ...              ...        ...   \n",
       "1995    Ron White: You Can't Fix Stupid              7.4        N/A   \n",
       "1996               A Grin Without A Cat              8.0         81   \n",
       "1997                Le chant du Styrène              7.0        N/A   \n",
       "1998  Prison Break: The Road to Freedom              8.4        N/A   \n",
       "1999            The Lovers & the Despot              6.5         65   \n",
       "\n",
       "     Number of Votes_IMDB Running Time          Release Date_IMDB  \\\n",
       "0                 138,833           2h     15 November 2002 (USA)   \n",
       "1                 125,629      2h 2min         25 June 2004 (USA)   \n",
       "2                 100,146     1h 40min         11 June 2004 (USA)   \n",
       "3                  80,546     1h 27min      25 October 2002 (USA)   \n",
       "4                  79,832     1h 36min         30 June 2006 (USA)   \n",
       "...                   ...          ...                        ...   \n",
       "1995                  914           1h   TV Special 25 March 2006   \n",
       "1996                  914           4h  23 November 1977 (France)   \n",
       "1997                  914        13min     November 1958 (France)   \n",
       "1998                  913        22min   TV Short 13 January 2007   \n",
       "1999                  912     1h 38min    23 September 2016 (USA)   \n",
       "\n",
       "              Director  \n",
       "0        Michael Moore  \n",
       "1        Michael Moore  \n",
       "2      Morgan Spurlock  \n",
       "3        Jeff Tremaine  \n",
       "4     Davis Guggenheim  \n",
       "...                ...  \n",
       "1995     Michael Drumm  \n",
       "1996      Chris Marker  \n",
       "1997     Alain Resnais  \n",
       "1998       Jim Barrett  \n",
       "1999         Ross Adam  \n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = dict({'Title':titles, 'User Rating_IMDB':user_rating, 'Metacritic':metacritic, 'Number of Votes_IMDB': num_votes, 'Running Time': running_time, 'Release Date_IMDB': release_date, 'Director':director})\n",
    "df = pd.DataFrame(dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('IMDB_byVote.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3a9220a3698e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IMDB_byVote.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2671\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m     def to_clipboard(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"IMDB_byVote.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "source_code_1 = requests.get('https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250')\n",
    "soup = BeautifulSoup(source_code_1.text, 'html5lib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250&start=251&ref_=adv_nxt', 'https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250&start=501&ref_=adv_nxt', 'https://www.imdb.com/search/title/?genres=documentary&countries=us&count=250&start=751&ref_=adv_nxt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(soup):\n",
    "    titles_interim =[]\n",
    "    titles = []\n",
    "    results = soup.find_all(class_='lister-item-content')\n",
    "    for i in range(len(results)):\n",
    "        title = results[i].find('a').contents\n",
    "        titles_interim.append(title)\n",
    "    for i in titles_interim:\n",
    "        titles.append(i[0])\n",
    "    return titles\n",
    "titles = get_titles(soup)\n",
    "titles\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(soup):\n",
    "    links = []\n",
    "    results = soup.find_all(class_='lister-item-content')\n",
    "    for i in range(len(results)):\n",
    "        link = results[i].find('a').get('href')\n",
    "        full_link = \"https://www.imdb.com\" + link + \"?ref_=adv_li_tt\"\n",
    "        links.append(full_link)\n",
    "    return links\n",
    "imdb_250 = (get_links(soup))\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating = []\n",
    "metacritic = []\n",
    "num_votes = []\n",
    "running_time=[]\n",
    "release_date = []\n",
    "director = []\n",
    "\n",
    "def imdb_data(links):\n",
    "    movie_dict = {}\n",
    "    for link in links[:20]:\n",
    "        soup = BeautifulSoup(requests.get(link).text, \"html5lib\")\n",
    "        user_rating.append(soup.find(itemprop='ratingValue').text)\n",
    "        try:\n",
    "            num_votes.append(soup.find('span', class_='small', itemprop='ratingCount').text)\n",
    "        except AttributeError:\n",
    "            num_votes.append('N/A')\n",
    "        try:\n",
    "            running_time.append(soup.find('div', class_='subtext').time.text.strip())\n",
    "        except AttributeError:\n",
    "            running_time.append('N/A')\n",
    "        try:\n",
    "            release_date.append(soup.find('a', title='See more release dates').text.strip())\n",
    "        except AttributeError:\n",
    "            release_date.append('N/A')\n",
    "        try:\n",
    "            director.append(soup.find_all('div', class_='credit_summary_item')[0].a.text)\n",
    "        except AttributeError:\n",
    "            director.append('N/A')\n",
    "        try:\n",
    "            metacritic.append(soup.find(class_='metacriticScore score_favorable titleReviewBarSubItem').text.strip())\n",
    "        except AttributeError:\n",
    "            metacritic.append('N/A')\n",
    "    return user_rating, metacritic, num_votes, running_time, release_date, director\n",
    "\n",
    "print(imdb_data(imdb_250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dict({'Title':titles[:20], 'User Rating':user_rating, 'Metacritic':metacritic, 'Number of Votes': num_votes, 'Running Time': running_time, 'Release Date': release_date, 'Director':director})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_1_movie = BeautifulSoup(requests.get(imdb_250[1]).text, 'html5lib')\n",
    "soup_1_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating = soup_1_movie.find(itemprop='ratingValue').text\n",
    "user_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    metacritic = soup_1_movie.find(class_='metacriticScore score_favorable titleReviewBarSubItem').text.replace(\"\\n\",\"\")\n",
    "except AttributeError:\n",
    "    metacritic = 'N/A'\n",
    "metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = soup_1_movie.find('span', class_='small', itemprop='ratingCount').text\n",
    "vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time = soup_1_movie.find('div', class_='subtext').time.text.strip()\n",
    "running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date = soup_1_movie.find('a', title='See more release dates').text.strip()\n",
    "release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director = soup_1_movie.find_all('div', class_='credit_summary_item')[0].a.text\n",
    "director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article_title = soup.find('h1', class_='header').text.replace('\\n','')\n",
    "content = soup.find(id='main')\n",
    "movie_frame = content.find_all('div', class_="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
